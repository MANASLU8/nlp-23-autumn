{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory work #4 (text classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors_read = {}\n",
    "\n",
    "with open('../assets/annotated-corpus/test-embeddings.tsv', 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split('\\t')\n",
    "        doc_id = parts[0]\n",
    "        vector = list(map(float, parts[1:]))\n",
    "        test_vectors_read[doc_id] = vector\n",
    "        \n",
    "test_embeddings = pd.DataFrame(test_vectors_read).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for root, dirs, files in os.walk('../assets/annotated-corpus'):\n",
    "    for file in files:\n",
    "        if file.endswith('.tsv'):\n",
    "            parts = root.split(os.sep)\n",
    "            if len(parts) >= 2:\n",
    "                train_test_val = parts[-2]  # train/test/val part\n",
    "                fake_true = parts[-1]       # fake/true class\n",
    "                document_index = file.split('.')[0]  # document index\n",
    "\n",
    "                if train_test_val == 'assets':\n",
    "                    continue\n",
    "                data.append([document_index, train_test_val, fake_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['document_index', 'part', 'class'])\n",
    "df.set_index('document_index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = test_embeddings.merge(df, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_embeddings.drop(['part', 'class'], axis=1)\n",
    "y = test_embeddings['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "    return np.nanmean(precision), np.nanmean(recall), np.nanmean(f1_score), np.nanmean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\n",
    "    'linear', \n",
    "    'poly', \n",
    "    'rbf', \n",
    "    'sigmoid'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = SVC(kernel=kernel)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision, recall, f1_score, accuracy = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'kernel': kernel,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best kernel: poly, because it is accurate and comparable fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_transform(x):\n",
    "    return x\n",
    "\n",
    "def add_transformed_features(X, func):\n",
    "    if func is not no_transform:\n",
    "        transformed_X = np.apply_along_axis(func, 1, X)\n",
    "        transformed_X = np.nan_to_num(transformed_X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return np.concatenate((X, transformed_X), axis=1)\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "def safe_sqrt(x):\n",
    "    return np.sqrt(np.abs(x))\n",
    "\n",
    "transformations = [no_transform, safe_sqrt, np.abs, np.log1p, np.cos, np.sin]\n",
    "results = []\n",
    "\n",
    "X_train_transformed = X_train.copy()\n",
    "X_test_transformed = X_test.copy()\n",
    "\n",
    "for transform in transformations:\n",
    "    X_train_transformed = add_transformed_features(X_train_transformed, transform)\n",
    "    X_test_transformed = add_transformed_features(X_test_transformed, transform)\n",
    "\n",
    "    model = SVC(kernel='poly')\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    precision, recall, f1_score, accuracy = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'transformation': transform.__name__,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'accuracy': accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding safe_sqrt is helpful, but other features are useless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
