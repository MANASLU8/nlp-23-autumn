{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T14:55:57.119575Z",
     "start_time": "2023-12-26T14:55:56.227992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/niruksorp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      3  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
      "1      3  Iraq Halts Oil Exports from Main Southern Pipe...\n",
      "2      3  Oil prices soar to all-time record, posing new...\n",
      "3      3  Stocks End Up, But Near Year Lows (Reuters). R...\n",
      "4      3  Money Funds Fell in Latest Week (AP). AP - Ass...\n",
      "Iraq Halts Oil Exports from Main Southern Pipeline (Reuters). Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df = pd.read_csv(os.path.join('data.csv'), names=['label', 'Title', 'Description'])\n",
    "df['text'] = (df['Title'] + '. ' + df['Description'])\n",
    "df.drop(columns=['Title', 'Description'], axis=1, inplace=True)\n",
    "print(df.head())\n",
    "print(df['text'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T14:56:03.130342Z",
     "start_time": "2023-12-26T14:56:02.812694Z"
    }
   },
   "id": "10d57caa4259352a"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "        label                                               text\n0           3  Carlyle Looks Toward Commercial Aerospace (Reu...\n1           3  Iraq Halts Oil Exports from Main Southern Pipe...\n2           3  Oil prices soar to all-time record, posing new...\n3           3  Stocks End Up, But Near Year Lows (Reuters). R...\n4           3  Money Funds Fell in Latest Week (AP). AP - Ass...\n...       ...                                                ...\n119993      1  Pakistan's Musharraf Says Won't Quit as Army C...\n119994      2  Renteria signing a top-shelf deal. Red Sox gen...\n119995      2  Saban not going to Dolphins yet. The Miami Dol...\n119996      2  Today's NFL games. PITTSBURGH at NY GIANTS Tim...\n119997      2  Nets get Carter from Raptors. INDIANAPOLIS -- ...\n\n[119998 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Stocks End Up, But Near Year Lows (Reuters). R...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Money Funds Fell in Latest Week (AP). AP - Ass...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119993</th>\n      <td>1</td>\n      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n    </tr>\n    <tr>\n      <th>119994</th>\n      <td>2</td>\n      <td>Renteria signing a top-shelf deal. Red Sox gen...</td>\n    </tr>\n    <tr>\n      <th>119995</th>\n      <td>2</td>\n      <td>Saban not going to Dolphins yet. The Miami Dol...</td>\n    </tr>\n    <tr>\n      <th>119996</th>\n      <td>2</td>\n      <td>Today's NFL games. PITTSBURGH at NY GIANTS Tim...</td>\n    </tr>\n    <tr>\n      <th>119997</th>\n      <td>2</td>\n      <td>Nets get Carter from Raptors. INDIANAPOLIS -- ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>119998 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T08:26:26.350381Z",
     "start_time": "2023-12-13T08:26:26.319540Z"
    }
   },
   "id": "ad6c6f57643b7841"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_to_sent(text):\n",
    "    sentences = re.split(\n",
    "        r\"(((?<!\\w\\.\\w.)(?<!\\s\\w\\.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s(?=[A-Z]))|((?<![\\,\\-\\:])\\n(?=[A-Z]|\\\" )))\", text)[\n",
    "                ::4]\n",
    "    return sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:46:54.718808Z",
     "start_time": "2023-12-13T14:46:54.705928Z"
    }
   },
   "id": "f16b78e23c14172f"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def split_to_words(sentence):\n",
    "    words = re.findall(r\"\\w+@\\w+\\.\\w+|\\+\\d{1,3}-\\d{3}-\\d{3}-\\d{2}-\\d{2}|\\w+\", sentence)\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:46:56.138322Z",
     "start_time": "2023-12-13T14:46:56.129938Z"
    }
   },
   "id": "bded99f420ae9022"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/niruksorp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def process_file():\n",
    "    wnl = WordNetLemmatizer()\n",
    "    sst = SnowballStemmer(\"english\")\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        sentences = split_to_sent(row['text'])\n",
    "        words_dic = []\n",
    "        counter += 1\n",
    "        for s in sentences:\n",
    "            words_dic += split_to_words(s)\n",
    "            words_dic.append(\"\\n\")\n",
    "        lemmatized = []\n",
    "        stemmed = []\n",
    "        original = []\n",
    "        for w in words_dic:\n",
    "            w_processed = re.sub(r\"[.!?,]$\", \"\", w).lower() # убрать удаление точек и etc. отделить от токена и сохранить отдлеьно (1 балл доделать)\n",
    "            lemmatized.append(wnl.lemmatize(w_processed))\n",
    "            stemmed.append(sst.stem(w_processed))\n",
    "            original.append(w_processed)\n",
    "        save_to_file(original, lemmatized, stemmed, os.path.join(\".\", \"assets\", \"annotated-corpus\", \"train\", str(row['label']), str(counter) + \".tsv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:53:58.097527Z",
     "start_time": "2023-12-13T14:53:58.005432Z"
    }
   },
   "id": "b2f4a0464b92971e"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "def save_to_file(original, lemmatized, stemmed, id):\n",
    "    with open(id, \"w\") as f:\n",
    "        for i in range(len(original)):\n",
    "            if original[i] == \"\\n\":\n",
    "                 print(\"\", file=f)\n",
    "            else:\n",
    "                print(original[i], stemmed[i], lemmatized[i], sep=\"\\t\", file=f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:53:41.298574Z",
     "start_time": "2023-12-13T14:53:41.288307Z"
    }
   },
   "id": "eae86957a0812dbe"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[193], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprocess_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[192], line 24\u001B[0m, in \u001B[0;36mprocess_file\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m     w_processed \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[.!?,]$\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, w)\u001B[38;5;241m.\u001B[39mlower()\n\u001B[1;32m     23\u001B[0m     lemmatized\u001B[38;5;241m.\u001B[39mappend(wnl\u001B[38;5;241m.\u001B[39mlemmatize(w_processed))\n\u001B[0;32m---> 24\u001B[0m     stemmed\u001B[38;5;241m.\u001B[39mappend(\u001B[43msst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw_processed\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     25\u001B[0m     original\u001B[38;5;241m.\u001B[39mappend(w_processed)\n\u001B[1;32m     26\u001B[0m save_to_file(original, lemmatized, stemmed, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massets\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mannotated-corpus\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]), \u001B[38;5;28mstr\u001B[39m(counter) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.tsv\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject3/venv/lib/python3.9/site-packages/nltk/stem/snowball.py:1703\u001B[0m, in \u001B[0;36mEnglishStemmer.stem\u001B[0;34m(self, word)\u001B[0m\n\u001B[1;32m   1700\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1702\u001B[0m \u001B[38;5;66;03m# STEP 3\u001B[39;00m\n\u001B[0;32m-> 1703\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m suffix \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__step3_suffixes\u001B[49m:\n\u001B[1;32m   1704\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m word\u001B[38;5;241m.\u001B[39mendswith(suffix):\n\u001B[1;32m   1705\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m r1\u001B[38;5;241m.\u001B[39mendswith(suffix):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "process_file()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:55:29.941546Z",
     "start_time": "2023-12-13T14:54:00.119311Z"
    }
   },
   "id": "9dc8c43fc3a82676"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
