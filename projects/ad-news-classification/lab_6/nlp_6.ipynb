{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nljr_QOTolpU",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d_UCwJmyop9U",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R-7HqqlWodjc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "\n",
    "class EmbeddingFunction:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.model.encode(input).tolist()\n",
    "\n",
    "\n",
    "class DB:\n",
    "    def __init__(self, distance_function, root_path):\n",
    "        self.ef = EmbeddingFunction()\n",
    "        self.client = chromadb.PersistentClient(path=root_path)\n",
    "        self.distance_function = distance_function\n",
    "        assert distance_function in [\"l2\", \"ip\", \"cosine\"], \"Distance function should be 'l2' or 'ip' or 'cosine'\"\n",
    "        self.collection = self.client.get_or_create_collection(\"lab5_\" + self.distance_function,\n",
    "                                                               metadata={\"hnsw:space\": self.distance_function},\n",
    "                                                               embedding_function=self.ef)\n",
    "\n",
    "    def add(self, items):\n",
    "        old_batch = 0\n",
    "        new_batch = 1000\n",
    "        while True:\n",
    "            if new_batch > len(items[\"fragments\"]):\n",
    "                break\n",
    "            self.collection.add(\n",
    "                documents=items[\"fragments\"][old_batch:new_batch],\n",
    "                metadatas=items[\"metadata\"][old_batch:new_batch],\n",
    "                ids=items[\"ids\"][old_batch:new_batch])\n",
    "            old_batch = new_batch\n",
    "            new_batch += 1000\n",
    "        self.collection.add(\n",
    "            documents=items[\"fragments\"][old_batch:],\n",
    "            metadatas=items[\"metadata\"][old_batch:],\n",
    "            ids=items[\"ids\"][old_batch:])\n",
    "\n",
    "    def query(self, query, n_results):\n",
    "        return self.collection.query(query_embeddings=self.ef(query), n_results=n_results)\n",
    "\n",
    "    def clear(self):\n",
    "        self.client.delete_collection(\"lab5_\" + self.distance_function)\n",
    "        self.collection = self.client.get_or_create_collection(\"lab5_\" + self.distance_function,\n",
    "                                                               metadata={\"hnsw:space\": self.distance_function},\n",
    "                                                               embedding_function=self.ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d557bd839db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_l2 = DB(\"l2\", \"/content/drive/MyDrive/ITMO/NLP/lab5/DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rdw3gUlZ8XHq",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sP88_bZK9FKs",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken\n",
    "!pip install openai\n",
    "!pip install cohere\n",
    "!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UmGPq1_v8bjq",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio==3.48.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f34c2a256f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UKpDk97j8Ku9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", model_file=\"mistral-7b-openorca.Q2_K.gguf\", model_type=\"mistral\", gpu_layers=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FRcCpY7L8SYZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_request(message, history):\n",
    "    context = \"\\n\".join(database_l2.query(message, 5)[\"documents\"][0])\n",
    "    prompt = \"Answer the question using provided context. Your answer should be in your own words and be no longer than 50 words.\\n\"\n",
    "    prompt += \"Context: \" + context + \"\\n\"\n",
    "    prompt += \"Question: \" + message + \"\\n\"\n",
    "    prompt += \"Answer: \"\n",
    "    answer = llm(prompt)\n",
    "    return f\"{prompt}\\n\\n{answer}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CU7JfHNshfWl",
   "metadata": {
    "id": "CU7JfHNshfWl"
   },
   "source": [
    "1. Проблемы фондового рынка в разгар летнего спада?\n",
    "2. Что говорится в рекомендации по безопасности?\n",
    "3. Кому проиграл Трит Хьюи?\n",
    "4. Что вызвало гнев азиатских соседей?\n",
    "5. Где жили НАТО когда прибыли в Боснию?\n",
    "6. Как звали первых клонированных кошек?\n",
    "7. Кто такой Шумахер?\n",
    "8. Кто такой Путин?\n",
    "9. Почему Владимир Путин молодец?\n",
    "0. Почему Трамп победил на выборах?\n",
    "11. Как вернуться в 2007?\n",
    "12. Раньше было лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VhXenHysDW5U",
   "metadata": {
    "id": "VhXenHysDW5U"
   },
   "source": [
    "1. 655 Что улучшит состояние пациентов находящихся на диализе? 655\n",
    "What will improve the condition of patients on dialysis?\n",
    "2. Как изменились зарплаты топ менеджеров?\n",
    "How have the salaries of top managers changed?\n",
    "3. 709 How do they work to improve their image? Как работают над улучшением имиджа?\n",
    "4. 839 На что влияют рейды ополченцев? What is the impact of militiamen raids?\n",
    "5. 1006 Какой ущерб от урагана Чарли во флориде?\n",
    "How much damage did Hurricane Charlie cause in Florida?\n",
    "6. 1047 Какие инциденты происходили на атомной электростанции? What incidents occurred at a nuclear power plant?\n",
    "7. 1150 Что сейчас с тренером Los Angeles Galaxy?\n",
    "What's up with the Los Angeles Galaxy coach now?\n",
    "8. 1240 Какую партию США называют террористической? Which US party is called terrorist?\n",
    "9. 1287 In which players renew their vows as teammates? Какие игроки возобновляют свои клятвы товарищей по команде?\n",
    "10. 1337 Что происходит в Багдаде? What's happening in Baghdad?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8TllDMH-8WRe",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(fn=process_request, title=\"Chat bot\")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
