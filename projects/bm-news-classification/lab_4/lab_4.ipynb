{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866709bfce1891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e6f20e19aabd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\"tensorboard_logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = \"../assets/annotated-corpus/train_embeddings.tsv\"\n",
    "test_embeddings = \"../assets/annotated-corpus/test_embeddings.tsv\"\n",
    "topics = os.listdir(\"../assets/annotated-corpus/train\")\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3ab3b728d560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(filename):\n",
    "    x_raw = []\n",
    "    y_raw = []\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()[:-1]\n",
    "        for line in lines:\n",
    "            y_raw.append(topics.index(line.split(\"\\t\", 1)[0].split(\"/\")[0]))\n",
    "            x_raw.append(list(map(float, line.split(\"\\t\", 1)[1].split(\"\\t\"))))\n",
    "\n",
    "    return np.array(x_raw), np.array(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559fe9e7321a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_dataset(train_embeddings)\n",
    "x_test, y_test = prepare_dataset(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s-XgTBnLhoAF",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0c5080075d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b784bd42837f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-y_p71KHkMy1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = len(x_test[0])\n",
    "for l in range(len(x_test)):\n",
    "  if len(x_test[l]) != ln:\n",
    "    print(f\"trouble at: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cae70deec8bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6aa5ec5ebf7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raw_metrics(pred, gt):\n",
    "    metrics_dict = {}\n",
    "    if pred.shape != gt.shape:\n",
    "        raise RuntimeError(\"Shapes doesn't fit\")\n",
    "    for i in gt:\n",
    "        if i not in metrics_dict.keys():\n",
    "             metrics_dict[i] = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "    for i in range(pred.shape[0]):\n",
    "        if pred[i] == gt[i]:\n",
    "            metrics_dict[gt[i]][\"tp\"] += 1\n",
    "            for j in metrics_dict.keys():\n",
    "                if j != gt[i]:\n",
    "                    metrics_dict[j][\"tn\"] += 1\n",
    "        else:\n",
    "            metrics_dict[pred[i]][\"fp\"] += 1\n",
    "            metrics_dict[gt[i]][\"fn\"] += 1\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bb72e1ca273d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, gt):\n",
    "    raw_dict = calculate_raw_metrics(pred, gt)\n",
    "    metrics_dict = {}\n",
    "    global_tp = 0\n",
    "    global_fp = 0\n",
    "    global_tn = 0\n",
    "    global_fn = 0\n",
    "    metrics_dict[\"precision_macro\"] = 0\n",
    "    metrics_dict[\"recall_macro\"] = 0\n",
    "    metrics_dict[\"f1_macro\"] = 0\n",
    "\n",
    "    for i in raw_dict.keys():\n",
    "        metrics_dict[i] = {}\n",
    "        metrics_dict[i][\"precision\"] = raw_dict[i][\"tp\"] / (raw_dict[i][\"tp\"] + raw_dict[i][\"fp\"])\n",
    "        metrics_dict[i][\"recall\"] = raw_dict[i][\"tp\"] / (raw_dict[i][\"tp\"] + raw_dict[i][\"fn\"])\n",
    "        metrics_dict[i][\"f1\"] = 2 * raw_dict[i][\"tp\"] / (2 * raw_dict[i][\"tp\"] + raw_dict[i][\"fp\"] + raw_dict[i][\"fn\"])\n",
    "        global_tp += raw_dict[i][\"tp\"]\n",
    "        global_tn += raw_dict[i][\"tn\"]\n",
    "        global_fn += raw_dict[i][\"fn\"]\n",
    "        global_fp += raw_dict[i][\"fp\"]\n",
    "        metrics_dict[\"precision_macro\"] += metrics_dict[i][\"precision\"] / len(raw_dict.keys())\n",
    "        metrics_dict[\"recall_macro\"] += metrics_dict[i][\"recall\"] / len(raw_dict.keys())\n",
    "        metrics_dict[\"f1_macro\"] += metrics_dict[i][\"f1\"] / len(raw_dict.keys())\n",
    "\n",
    "    metrics_dict[\"precision_micro\"] = global_tp / (global_tp + global_fp)\n",
    "    metrics_dict[\"recall_micro\"] = global_tp / (global_tp + global_fn)\n",
    "    metrics_dict[\"f1_micro\"] = 2 * global_tp / (2 * global_tp + global_fn + global_fp)\n",
    "    metrics_dict[\"accuracy\"] = global_tp / gt.shape[0]\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8f8b8ab452c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_metrics(pred, gt):\n",
    "    print(\"Precision:\", precision_score(gt, pred, average=None))\n",
    "    print(\"Recall:\", recall_score(gt, pred, average=None))\n",
    "    print(\"F1:\", f1_score(gt, pred, average=None))\n",
    "    print(\"Precision macro:\", precision_score(gt, pred, average=\"macro\"))\n",
    "    print(\"Recall macro:\", recall_score(gt, pred, average=\"macro\"))\n",
    "    print(\"F1 macro:\", f1_score(gt, pred, average=\"macro\"))\n",
    "    print(\"Precision micro:\", precision_score(gt, pred, average=\"micro\"))\n",
    "    print(\"Recall micro:\", recall_score(gt, pred, average=\"micro\"))\n",
    "    print(\"F1 micro:\", f1_score(gt, pred, average=\"micro\"))\n",
    "    print(\"Accuracy:\", accuracy_score(gt, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e9f74a1a86039",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ad66726634bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493b4070b57a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    t_begin = time.time()\n",
    "    model.fit(x_train, y_train, )\n",
    "    t_end = time.time()\n",
    "    preds = model.predict(x_test)\n",
    "    metrics = calculate_metrics(preds, y_test)\n",
    "    print(\"Precision macro:\", metrics[\"precision_macro\"])\n",
    "    print(\"Recall macro:\", metrics[\"recall_macro\"])\n",
    "    print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
    "    print(\"Precision micro:\", metrics[\"precision_micro\"])\n",
    "    print(\"Recall micro:\", metrics[\"recall_micro\"])\n",
    "    print(\"F1 micro:\", metrics[\"f1_micro\"])\n",
    "    print(\"Accuracy:\", metrics[\"accuracy\"])\n",
    "    print(\"Time:\", t_end - t_begin)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31d6082213eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = train_evaluate_model(SVC(kernel=\"linear\"), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffb2df944f3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = train_evaluate_model(SVC(kernel=\"poly\"), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889f2239083feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = train_evaluate_model(SVC(kernel=\"rbf\"), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be8cfa6c9a79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid = train_evaluate_model(SVC(kernel=\"sigmoid\"), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7KTKSxazpkPy",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b11225b7cf2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed87d8692038a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 4),\n",
    "            torch.nn.Softmax(dim=0)\n",
    "        )\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[:, :100]\n",
    "        y = batch[:, 100:]\n",
    "        y_hat = self.layers(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[:, :100]\n",
    "        y = batch[:, 100:]\n",
    "        y_hat = self.layers(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=1e-5,\n",
    "                                     weight_decay=1e-8)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e1256251710a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = torch.nn.functional.one_hot(torch.tensor(y_train, dtype=torch.int64), num_classes = 4).float()\n",
    "data = torch.cat((torch.tensor(x_train, dtype=torch.float32), y_train_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8mwIKAXQoVm",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_onehot = torch.nn.functional.one_hot(torch.tensor(y_test, dtype=torch.int64), num_classes = 4).float()\n",
    "data_test = torch.cat((torch.tensor(x_test, dtype=torch.float32), y_test_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4d012eeef4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorboardx\n",
    "!pip3 install -U tensorboardx\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m venv venv  # создание виртуальной среды\n",
    "!{sys.executable} -m pip install -U tensorboard tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dfb3f54f4e5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=data, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_test, batch_size=32, shuffle=False)\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "logger = pl.loggers.TensorBoardLogger(\"tensorboard_logs/\")\n",
    "trainer = pl.Trainer(max_epochs=200, logger=logger)\n",
    "from lightning_utilities.core.imports import RequirementCache\n",
    "\n",
    "print(RequirementCache(\"tensorboard\"))\n",
    "print(RequirementCache(\"tensorboardx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6835339b465200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "trainer.fit(mlp, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1941ea8e93ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(mlp.forward(torch.tensor(x_test).float()).detach(), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3069b204f442ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4ca79f91653f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d60b2f5993af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200bc8f9cf85d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:9000], y_train[perm][:9000], x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6264ed5a22e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:6000], y_train[perm][:6000], x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0227c38206914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:2000], y_train[perm][:2000], x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f21f50a1f5aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[:, 10:90], y_train, x_test[:, 10:90], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2c7eef2c62966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9d7a7deb30f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), pca.transform(x_train), y_train, pca.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d30990ba0093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9191df8225e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data = pca_2.fit_transform(x_train[perm][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0b48efcf58d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e4392676a9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31685c23179e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(draw_data[:, 0], draw_data[:, 1], c=y_train[perm][:500], cmap=\"tab20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8449cabae1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_extended = np.concatenate((x_train, np.sin(x_train), np.cos(x_train)), axis=1)\n",
    "x_test_extended = np.concatenate((x_test, np.sin(x_test), np.cos(x_test)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95836e94623574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141dc5c5282dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train_extended, y_train, x_test_extended, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNJ8de6pchho",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
