{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27d8m4syMVx5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#, force_remount=True)"
      ],
      "id": "27d8m4syMVx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XLFeO16MYJ_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "project_path = 'drive/MyDrive/Сертификат/news-dataset/'"
      ],
      "id": "4XLFeO16MYJ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "405d38f1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops = set(stopwords.words('english'))"
      ],
      "id": "405d38f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ff4727a8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "all_lemmas = []\n",
        "for train_idx in ['1', '2', '3', '4']:\n",
        "    c = pd.read_csv(f\"drive/MyDrive/Сертификат/news-dataset/assets/annotated-corpus/train/{train_idx}.tsv\",delimiter='\\t')\n",
        "    sentence_lemmas=[]\n",
        "    prev_doc_id = c.values[0][0]\n",
        "    for el in  tqdm(c.values):\n",
        "        lemma = el[3]\n",
        "        if el[1]==\"\\n\":\n",
        "            continue\n",
        "        if el[0]!=prev_doc_id:\n",
        "            all_lemmas.append((prev_doc_id, sentence_lemmas))\n",
        "            sentence_lemmas=[]\n",
        "            prev_doc_id=el[0]\n",
        "        else:\n",
        "            if type(lemma) == str:\n",
        "                lemma_filtered = re.sub(r'[^\\w\\s]','', lemma)\n",
        "                if len(lemma_filtered)==0 or lemma_filtered in stops:\n",
        "                    continue\n",
        "                sentence_lemmas.append(lemma_filtered.lower())\n"
      ],
      "id": "ff4727a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0e73ef8d"
      },
      "outputs": [],
      "source": [
        "N = len(all_lemmas)"
      ],
      "id": "0e73ef8d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2f74d2b4"
      },
      "outputs": [],
      "source": [
        "all_words = [el for sentence in all_lemmas for el in sentence[1]]"
      ],
      "id": "2f74d2b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0c78d093"
      },
      "outputs": [],
      "source": [
        "len(all_words)"
      ],
      "id": "0c78d093"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f46da3b5"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "word_cnt = Counter(all_words)"
      ],
      "id": "f46da3b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c62b6563"
      },
      "outputs": [],
      "source": [
        "len(word_cnt)"
      ],
      "id": "c62b6563"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "224f50b6"
      },
      "outputs": [],
      "source": [
        "word_cnt = Counter({k: c for k, c in word_cnt.most_common(8192)})"
      ],
      "id": "224f50b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0664b26f"
      },
      "outputs": [],
      "source": [
        "word_cnt"
      ],
      "id": "0664b26f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "06d438e2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"tokens_freq.json\", \"w\") as file:\n",
        "    json.dump(word_cnt, file)"
      ],
      "id": "06d438e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d5aa836f"
      },
      "outputs": [],
      "source": [
        "def create_term_document_matrix(documents, token_freq):\n",
        "    matrix = []\n",
        "    token_freq = list(token_freq.keys())\n",
        "    for doc in tqdm(documents[:60000]):\n",
        "        tokens = doc[1]\n",
        "        tokens_cnt = Counter(tokens)\n",
        "        row = [tokens_cnt[token.lower()] for token in token_freq]\n",
        "        matrix.append(row)\n",
        "\n",
        "    return matrix"
      ],
      "id": "d5aa836f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "648f3166"
      },
      "outputs": [],
      "source": [
        "len(word_cnt)"
      ],
      "id": "648f3166"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MQJ3Bf4yFtpz"
      },
      "outputs": [],
      "source": [
        "len(all_lemmas)"
      ],
      "id": "MQJ3Bf4yFtpz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c51b894a"
      },
      "outputs": [],
      "source": [
        "term_doc_matrix = create_term_document_matrix(all_lemmas,word_cnt)"
      ],
      "id": "c51b894a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f984bb0a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"term_document_matrix.json\", \"w\") as file:\n",
        "    json.dump(term_doc_matrix, file)"
      ],
      "id": "f984bb0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "084ba58b"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "id": "084ba58b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNYpbWGFlE-K"
      },
      "outputs": [],
      "source": [
        "# Перезагрузочка\n",
        "import numpy as np"
      ],
      "id": "PNYpbWGFlE-K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdaWoRL5TNxa"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"drive/MyDrive/Сертификат/news-dataset/assets/tokens_freq.json\", \"r\") as file:\n",
        "    word_cnt = json.load(file)"
      ],
      "id": "AdaWoRL5TNxa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB2_em6tUKGq"
      },
      "outputs": [],
      "source": [
        "word_cnt"
      ],
      "id": "UB2_em6tUKGq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30Gmp5_jk9qq"
      },
      "outputs": [],
      "source": [
        "#import json\n",
        "#with open(\"term_document_matrix.json\", \"r\") as file:\n",
        "#    term_doc_matrix = json.load(file)"
      ],
      "id": "30Gmp5_jk9qq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tzr7q8LlKOu"
      },
      "outputs": [],
      "source": [],
      "id": "4tzr7q8LlKOu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba2b325c"
      },
      "outputs": [],
      "source": [
        "term_doc_matrix = np.array(term_doc_matrix)"
      ],
      "id": "ba2b325c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e42c7cda"
      },
      "outputs": [],
      "source": [
        "term_doc_matrix.shape"
      ],
      "id": "e42c7cda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43da3121"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "from tqdm import tqdm\n",
        "IDF = {}\n",
        "terms = list(word_cnt.keys())\n",
        "for i in tqdm(range(len(terms))):\n",
        "    IDF[i] = log( (1+N) / (1+np.count_nonzero(term_doc_matrix[:,i]) ))"
      ],
      "id": "43da3121"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a72de6a"
      },
      "outputs": [],
      "source": [
        "term_doc_matrix[0].shape"
      ],
      "id": "7a72de6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed808c52"
      },
      "outputs": [],
      "source": [
        "def compute_tf_idf(term_document_matrix, terms):\n",
        "    tf_idf_matrix = []\n",
        "    for document in tqdm(term_document_matrix):\n",
        "        tf_idf_row=[]\n",
        "        for i in range(len(terms)):\n",
        "            tf = document[i]\n",
        "            tf_idf_row.append(tf * IDF[i])\n",
        "        tf_idf_matrix.append(tf_idf_row)\n",
        "\n",
        "    return tf_idf_matrix"
      ],
      "id": "ed808c52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb627a7c"
      },
      "outputs": [],
      "source": [
        "tf_idf_matrix = compute_tf_idf(term_doc_matrix[:10000], terms)"
      ],
      "id": "cb627a7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d544a06"
      },
      "outputs": [],
      "source": [
        "tf_idf_matrix_np = np.array(tf_idf_matrix)"
      ],
      "id": "6d544a06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ff5cb3e"
      },
      "outputs": [],
      "source": [
        "tf_idf_matrix_np.shape"
      ],
      "id": "6ff5cb3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95c98cc3"
      },
      "outputs": [],
      "source": [
        "vec = tf_idf_matrix[0]\n",
        "print(vec)"
      ],
      "id": "95c98cc3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlA-lB4HqEkc"
      },
      "outputs": [],
      "source": [
        "# 3"
      ],
      "id": "jlA-lB4HqEkc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ef5189f"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences=[el[1] for el in all_lemmas[:]], vector_size=256, window=5, min_count=1, workers=14)\n",
        "model.save(\"word2vec.model\")"
      ],
      "id": "9ef5189f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc7c1e65"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")"
      ],
      "id": "fc7c1e65"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88599611"
      },
      "outputs": [],
      "source": [
        "model.train([el[1] for el in all_lemmas[:]], total_examples=len(all_lemmas[:]), epochs=100)"
      ],
      "id": "88599611"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90abf545"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance\n",
        "1 - distance.cosine(model.wv[\"winter\"], model.wv[\"summer\"])"
      ],
      "id": "90abf545"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f4f3749"
      },
      "outputs": [],
      "source": [
        "np.dot(model.wv[\"winter\"], model.wv[\"summer\"])/(np.linalg.norm(model.wv[\"winter\"])*np.linalg.norm(model.wv[\"summer\"]))"
      ],
      "id": "5f4f3749"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd0135e7"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def cosine_similarity(v1,v2):\n",
        "    dot_product, norm1, norm2 = 0, 0, 0\n",
        "    for i in range(len(v1)):\n",
        "        x = v1[i]\n",
        "        y = v2[i]\n",
        "        dot_product+=x*y\n",
        "        norm1 += x*x\n",
        "        norm2 += y*y\n",
        "    norm1 = math.sqrt(norm1)\n",
        "    norm2 = math.sqrt(norm2)\n",
        "    return dot_product/(norm1*norm2)"
      ],
      "id": "dd0135e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a0d5fa4"
      },
      "outputs": [],
      "source": [
        "cosine_similarity(model.wv[\"winter\"], model.wv[\"summer\"])"
      ],
      "id": "1a0d5fa4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "727c0749"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "id": "727c0749"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb454b5a"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca1 = PCA(n_components=512)\n",
        "tf_idf_matrix_np_transformed = pca1.fit_transform(tf_idf_matrix_np.T)"
      ],
      "id": "bb454b5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2250369f"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "words = list(model.wv.key_to_index)\n",
        "X = [model.wv[word] for i, word in enumerate(words)]\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)"
      ],
      "id": "2250369f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aab0ab24"
      },
      "outputs": [],
      "source": [
        "for word in ['winter',\"snow\",\"summer\",\"hot\",\"cold\",\"bomb\",\"president\",\"cool\",\"heat\",\"sunday\",\"december\",\"july\"]:\n",
        "    vec = model.wv[word]\n",
        "    x,y = pca.transform(vec.reshape(1, -1))[0][0], pca.transform(vec.reshape(1, -1))[0][1]\n",
        "    plt.plot(x,y, 'o', color='red')\n",
        "    plt.annotate(word, (x, y))"
      ],
      "id": "aab0ab24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29b7a3c0"
      },
      "outputs": [],
      "source": [
        "tf_idf_matrix_np = np.array(tf_idf_matrix)"
      ],
      "id": "29b7a3c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a13ed303"
      },
      "outputs": [],
      "source": [
        "tf_idf_matrix_np #tf_idf_matrix_np_transformed"
      ],
      "id": "a13ed303"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "723f705c"
      },
      "outputs": [],
      "source": [
        "cosine_similarity(tf_idf_matrix_np_transformed[list(word_cnt.keys()).index(\"election\"),:], tf_idf_matrix_np_transformed[list(word_cnt.keys()).index(\"president\"),:])\n"
      ],
      "id": "723f705c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7115dc30"
      },
      "outputs": [],
      "source": [
        "cosine_similarity(tf_idf_matrix_np[:,list(word_cnt.keys()).index(\"election\")], tf_idf_matrix_np[:,list(word_cnt.keys()).index(\"president\")])\n"
      ],
      "id": "7115dc30"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c456eeaf"
      },
      "outputs": [],
      "source": [
        "cosine_similarity(model.wv[\"election\"], model.wv[\"president\"])\n"
      ],
      "id": "c456eeaf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34ad5362"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "def get_sentence_emb(sent):\n",
        "    sum_vector = np.zeros(256)\n",
        "    for token in sent:\n",
        "        try:\n",
        "            emb = model.wv[token]\n",
        "        except:\n",
        "            continue\n",
        "        sum_vector += emb\n",
        "    return sum_vector/len(sent)"
      ],
      "id": "34ad5362"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad8c7e65"
      },
      "outputs": [],
      "source": [
        "get_sentence_emb(all_lemmas[6][1])"
      ],
      "id": "ad8c7e65"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8685b32"
      },
      "outputs": [],
      "source": [
        "def embedd_csv_text(lemmas,test_idx):\n",
        "    for el in lemmas:\n",
        "        docid=el[0]\n",
        "        text=el[1]\n",
        "        with open(f\"drive/MyDrive/Сертификат/news-dataset/assets/annotated-corpus/train/{test_idx}_emb.tsv\", \"a\", encoding=\"utf-8\") as file:\n",
        "            embed = get_sentence_emb(text)\n",
        "            file.write(f\"{docid}\\t\")\n",
        "            for emb in embed:\n",
        "                file.write(f\"{emb}\\t\")\n",
        "            file.write(\"\\n\")"
      ],
      "id": "d8685b32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62fd64f9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "for test_idx in ['1', '2', '3', '4']:\n",
        "    test_all_lemmas = []\n",
        "    c = pd.read_csv(f\"drive/MyDrive/Сертификат/news-dataset/assets/annotated-corpus/train/{train_idx}.tsv\",delimiter='\\t')\n",
        "    sentence_lemmas=[]\n",
        "    prev_doc_id = c.values[0][0]\n",
        "    for el in  tqdm(c.values):\n",
        "        lemma = el[3]\n",
        "        if el[1]==\"\\n\":\n",
        "            continue\n",
        "        if el[0]!=prev_doc_id:\n",
        "            test_all_lemmas.append((prev_doc_id, sentence_lemmas))\n",
        "            sentence_lemmas=[]\n",
        "            prev_doc_id=el[0]\n",
        "        else:\n",
        "            if type(lemma) == str:\n",
        "                lemma_filtered = re.sub(r'[^\\w\\s]','', lemma)\n",
        "                if len(lemma_filtered)==0 or lemma_filtered in stops:\n",
        "                    continue\n",
        "                sentence_lemmas.append(lemma_filtered.lower())\n",
        "    embedd_csv_text(test_all_lemmas,test_idx)\n"
      ],
      "id": "62fd64f9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebe1854e"
      },
      "outputs": [],
      "source": [
        "len(test_all_lemmas)\n"
      ],
      "id": "ebe1854e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb5a46ba"
      },
      "outputs": [],
      "source": [],
      "id": "cb5a46ba"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}