{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#, force_remount=True)"
      ],
      "metadata": {
        "id": "0XvGUFK2hXWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "!pip install gradio==3.48.0\n",
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "LYRKiq6XhlWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5-__sbfhS4N"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model_emb = SentenceTransformer('BAAI/bge-large-en-v1.5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrM7H4KFhS4P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"drive/MyDrive/Сертификат/news-dataset/assets/test.csv\",header=None)\n",
        "data = data.values\n",
        "for i in range(len(data)):\n",
        "    data[i][0]=i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMWNW2O6hS4P"
      },
      "outputs": [],
      "source": [
        "all_embs =  []\n",
        "from tqdm import tqdm\n",
        "for el in tqdm(data):\n",
        "    embs = model_emb.encode([el[2]], normalize_embeddings=True)\n",
        "    all_embs.append((el[0],embs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "7aKdA3B-iKEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "HxdRFuET3JAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall fastapi==0.103.2"
      ],
      "metadata": {
        "id": "HbtGUSIP1t-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb"
      ],
      "metadata": {
        "id": "BMD_8FWUjg_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2Ophb49hS4Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "client = chromadb.Client()\n",
        "\n",
        "collection = client.create_collection(\"cos_db\", {\"hnsw:space\": \"cosine\"})\n",
        "abc = [el[1][0].tolist() for el in all_embs]\n",
        "collection.add(\n",
        "    embeddings=abc,\n",
        "    metadatas=[{\"headline\":el} for el in data[:,1].tolist()],\n",
        "    ids=[str(el[0]) for el in all_embs]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_zEzJ9bhS4R"
      },
      "outputs": [],
      "source": [
        "def get_documents(q):\n",
        "    instruction = \"Represent this sentence for searching relevant passages:\"\n",
        "    query = instruction + \" \" + q\n",
        "    query = model_emb.encode(query, normalize_embeddings=True)\n",
        "    results = collection.query(query_embeddings=[query.tolist()],n_results=10)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0y7nz5QhS4R"
      },
      "outputs": [],
      "source": [
        "def get_answer(question):\n",
        "    docs = [data[int(el)][2] for el in get_documents(question)[\"ids\"][0]]\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"Who are the founders of Microsoft?\",\n",
        "             \"Who is russia president?\",\n",
        "            \"Who is the mobile phone China leader?\",\n",
        "            \"Who first developed the theory of evolution\",\n",
        "            'What political party is currently in power in the United States?',\n",
        "             \"Where President Bush meets with Italian Prime Minister Silvio Berlusconi?\",\n",
        "             \"What is a record of global sales of mobile telephones?\",\n",
        "             \"Who was George Bush?\",\n",
        "             'What is the currency of Japan?',\n",
        "             'Who wrote the play \"Romeo and Juliet\"?']\n",
        "\n",
        "answers = [\"Bill Gates and Paul Allen\",\n",
        "           \"Vladimir Putin\",\n",
        "          \"Samsung\",\n",
        "          \"Charles Darwin\",\n",
        "           'The Democratic Party',\n",
        "           \"White House\",\n",
        "           \"156 mn.\",\n",
        "           'USA President',\n",
        "           'yen',\n",
        "           'William Shakespeare']"
      ],
      "metadata": {
        "id": "5hK0vqUKl8yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context1 = [get_answer(i) for i in questions]"
      ],
      "metadata": {
        "id": "-xKB770VhT7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALdRPTYUhS4S"
      },
      "outputs": [],
      "source": [
        "get_answer(\"Who was George Bush?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
        "\n",
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n"
      ],
      "metadata": {
        "id": "uxtOpohvaVN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs_all = []\n",
        "for q, a, index in zip(questions, answers, range(len(answers))):\n",
        "  QA_input = {'question': q,\n",
        "             'context': ' '.join(context1[index])}\n",
        "  res = nlp(QA_input)\n",
        "  bs = bertscore.compute(predictions=[res['answer']], references=[a], lang=\"en\")\n",
        "  bs_all.append(bs)\n",
        "\n",
        "  print(f'Question: {q}\\nAnswer: {res[\"answer\"]}\\nTrue answer: {a}\\nScore: {bs[\"f1\"][0]}\\n ')"
      ],
      "metadata": {
        "id": "hZqVIMK4aVLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = [bs['f1'][0] for bs in bs_all]\n",
        "sum(f1_scores)/len(f1_scores)"
      ],
      "metadata": {
        "id": "RpneOMS6eNdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEJeZn9FhS4W"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def echo(question, history):\n",
        "    QA_input = {'question': question,\n",
        "             'context': ' '.join(context1[1])}\n",
        "    res = nlp(QA_input)\n",
        "    return res['answer']\n",
        "\n",
        "demo = gr.ChatInterface(fn=echo, examples=[\"hello\", \"hola\", \"merhaba\"], title=\"Echo Bot\")\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}