{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder():\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        input = self.model.encode(input).tolist()\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaDB():\n",
    "    def __init__(self):\n",
    "        self.embedding_model = Embedder()\n",
    "        self.client = chromadb.PersistentClient(path='/media/space/ssd_1_tb_evo_sumsung/MishaHW/ChromaDB')\n",
    "        self.collection = self.client.get_or_create_collection(name=\"colls\", embedding_function=self.embedding_model)\n",
    "\n",
    "    def add_collection(self, all_fragments, all_metadate):\n",
    "        o_b = 0\n",
    "        b = 20000\n",
    "        ids = [str(i) for i in range(len(all_metadate))]\n",
    "        while True:\n",
    "            if b > len(all_fragments):\n",
    "                break\n",
    "            else:\n",
    "                self.collection.add(\n",
    "                    documents = all_fragments[o_b:b],\n",
    "                    embeddings = self.embedding_model(all_fragments[o_b:b]),\n",
    "                    metadatas = all_metadate[o_b:b],\n",
    "                    ids=ids[o_b:b]\n",
    "                )\n",
    "                o_b = b\n",
    "                b += 20000\n",
    "\n",
    "        self.collection.add(\n",
    "                    documents = all_fragments[o_b:b],\n",
    "                    embeddings = self.embedding_model(all_fragments[o_b:]),\n",
    "                    metadatas = all_metadate[o_b:],\n",
    "                    ids=ids[o_b:]\n",
    "                )\n",
    "        print(\"Data was loaded\")\n",
    "\n",
    "    def search(self, text, count = 1):\n",
    "        vector = self.embedding_model(text)\n",
    "        result = self.collection.query(\n",
    "            query_embeddings = vector,\n",
    "            n_results = count,\n",
    "            include=['distances','embeddings', 'documents', 'metadatas'],\n",
    "        )\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-OpenOrca-GGUF\", model_file=\"mistral-7b-openorca.Q4_K_M.gguf\", model_type=\"mistral\", gpu_layers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb = ChromaDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(message, history):\n",
    "    result = cdb.search(message, 1)\n",
    "    promt = f\"Context: {result['documents'][0][0]}.\" + f\"Question: {message}\"\n",
    "    answer = llm(promt)\n",
    "    metric = bertscore.compute(predictions=result['documents'][0], references=[message], model_type=\"distilbert-base-uncased\")\n",
    "    return f\"{answer}\" +f\"\\n\\nPrecision: {metric['precision'][0]}\" + f\"\\nRecall: {metric['recall'][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "ex = ['How old are you?', 'What is your favorite color?', 'Where were you born?', 'Do you have any siblings?']\n",
    "demo = gr.ChatInterface(fn=echo, examples=ex, title=\"Echo Bot\")\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
