{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_fragments(text, fragment_length=100):\n",
    "    fragments = [text[i:i+fragment_length] for i in range(0, len(text), fragment_length)]\n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author(text):\n",
    "    match = re.search(r'From:(.*?)(?=\\w+:|$)', text, re.DOTALL)\n",
    "    if match:\n",
    "        result = match.group(1).strip()\n",
    "        return result\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_dataset(dataset_path, len = 100):\n",
    "    all_fragments = list()\n",
    "    all_metadate = list()\n",
    "    catalogs = os.listdir(dataset_path)\n",
    "    for catalog in tqdm(catalogs):\n",
    "        path_catalog = os.path.join(f'{dataset_path}/{catalog}')\n",
    "        files = os.listdir(path_catalog)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(f'{path_catalog}/{file}')\n",
    "            with open(file_path, 'r', encoding='latin1') as file_name:\n",
    "                sample_content = file_name.read()\n",
    "                cleaned_text = sample_content.replace('\\t', ' ').replace('\\n', ' ')\n",
    "                cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "                fragments = split_into_fragments(cleaned_text)\n",
    "                author = find_author(sample_content)\n",
    "                count = 0\n",
    "                for fragment in fragments:\n",
    "                    meta_fragment = {'class': path_catalog.split('/')[-1],\n",
    "                                     'doc_fragment': f'{file}-{count}',\n",
    "                                     'author': author}\n",
    "                    all_metadate.append(meta_fragment)\n",
    "                    all_fragments.append(fragment)\n",
    "                    count += 1\n",
    "    return all_fragments, all_metadate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/space/ssd_1_tb_evo_sumsung/MishaHW/20news-bydate-train'\n",
    "all_fragments, all_metadate = processing_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class Embedder():\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        input = self.model.encode(input).tolist()\n",
    "        return input\n",
    "    \n",
    "embedder = Embedder()\n",
    "#embeddings = embedder.get_embeding(all_fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "class ChromaDB():\n",
    "    def __init__(self):\n",
    "        self.embedding_model = Embedder()\n",
    "        self.client = chromadb.PersistentClient(path='/media/space/ssd_1_tb_evo_sumsung/MishaHW/ChromaDB')\n",
    "        self.collection = self.client.get_or_create_collection(name=\"coll\", embedding_function=self.embedding_model)\n",
    "\n",
    "    def add_collection(self, all_fragments, all_metadate):\n",
    "        o_b = 0\n",
    "        b = 20000\n",
    "        ids = [str(i) for i in range(len(all_metadate))]\n",
    "        while True:\n",
    "            if b > len(all_fragments):\n",
    "                break\n",
    "            else:\n",
    "                self.collection.add(\n",
    "                    documents = all_fragments[o_b:b],\n",
    "                    embeddings = self.embedding_model(all_fragments[o_b:b]),\n",
    "                    metadatas = all_metadate[o_b:b],\n",
    "                    ids=ids[o_b:b]\n",
    "                )\n",
    "                o_b = b\n",
    "                b += 20000\n",
    "\n",
    "        self.collection.add(\n",
    "                    documents = all_fragments[o_b:b],\n",
    "                    embeddings = self.embedding_model(all_fragments[o_b:]),\n",
    "                    metadatas = all_metadate[o_b:],\n",
    "                    ids=ids[o_b:]\n",
    "                )\n",
    "        print(\"Data was loaded\")\n",
    "\n",
    "    def search(self, text, count = 1):\n",
    "        vector = self.embedding_model(text)\n",
    "        result = self.collection.query(\n",
    "            query_embeddings = vector,\n",
    "            n_results = count,\n",
    "            include=['distances','embeddings', 'documents', 'metadatas'],\n",
    "        )\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb = ChromaDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdb.add_collection(all_fragments, all_metadate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "count = 0\n",
    "for question in questions:\n",
    "    result = cdb.search(question[0], question[1])\n",
    "    print(f\"-----------Вопрос №{count}-----------\")\n",
    "    print(f\"Вопрос: {question[0]}\")\n",
    "    print(f\"Ответы: {result['documents']}\")\n",
    "    print()\n",
    "    count +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
