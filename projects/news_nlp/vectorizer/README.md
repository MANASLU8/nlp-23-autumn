## Лабораторная работа №3. Векторизация текста
**Задачи:**
<li> Построить словарь токенов с указанием их частот (словарь должен содержать как сами токены, так и количество их употреблений в обучающей выборке) и матрицу "термин-документ" (term-document matrix) <br>
<li> Реализовать один из базовых методов векторизации произвольного текста <br>
<li> Реализовать метод, позволяющий векторизовать произвольный текст с использованием нейронных сетей (предлагается использовать стандартную реализацию модели `w2v` или `glove`). Выбранную модель необходимо обучить на обучающей выборке. <br>
<li> С использованием библиотечной реализации метода подсчета косинусного расстояния между векторными представлениями текста, продемонстрировать на примерах, что для семантически близких слов модель генерирует вектора, для которых косинусное расстояние меньше, чем для семантически далеких токенов.  <br>
<li> Применить какой-либо метод сокращения размерностей полученных одним из базовых способов векторизации (в простейшем случае можно использовать метод `PCA`, допускается использование библиотечной реализации, сокращенная размерность должна быть сопоставима с размерностью векторов, формируемых векторной моделью. <br>
<li> С использованием разработанного метода подсчета косинусного расстояния сравнить эффективность метода векторизации с использованием нейронных сетей и эффективность базовых методов векторизации с последующим сокращением размерности. <br>
<li> Реализовать метод, осуществляющий векторизацию произвольного текста. <br>
<li> Выполнить векторизацию тестовой выборки с использованием метода, реализованного на предыдущем шаге. <br>

**Векторизация** - преобразование текста из символьного представления в последовательность вещественных чисел (векторов) заданного размера.

Для сравнения стандартной модели и с сокращенной размерностью было выбрано слово basketball <br>
Близкие по значению - `["football", "soccer"]` <br>
Из одной предметной области - `["sport", "players"]` <br>
Из разных предметных областей - `["yesterday", "fresh", "rules"]` 
<br>

**Вариант графика без использования PCA:** <br>
![basketball_example_plot](https://github.com/kivirciks/nlp-23-autumn/blob/main/projects/news_nlp/utils/basketball_example_plot.png) <br>
**Вариант графика с использованием PCA:** <br>
![basketball_example_plot](https://github.com/kivirciks/nlp-23-autumn/blob/main/projects/news_nlp/utils/basketball_example_PCA_plot.png)
<br>
Можно сделать вывод, что в данном случае модель с использованием сокращения размерности работает лучше.
