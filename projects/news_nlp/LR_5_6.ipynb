{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Лабораторная работа №5 (Поиск по векторной БД)**"
      ],
      "metadata": {
        "id": "0oVm-m7-58qN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlwYqVbKMsnZ"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install evaluate\n",
        "!pip install llama-cpp-python\n",
        "!pip install pinecone-client\n",
        "!pip install langchain==0.0.300\n",
        "!pip install chromadb==0.4.12\n",
        "!pip install sentence-transformers==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up5wARtwxmVd"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PDFMinerLoader, TextLoader, CSVLoader, UnstructuredWordDocumentLoader, UnstructuredHTMLLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import Document\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import Any\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebH-zobAxpPK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics\n",
        "import pinecone\n",
        "import glob\n",
        "import os\n",
        "import chromadb\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNzUR9kdjCHi",
        "outputId": "ebacc007-dec8-4671-e5df-26310f7915f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvCixdeK9PJM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/ITMO/nlp/train.csv', header=None, names = ['topic','title', 'text'])\n",
        "df['ID'] = df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A12sqg8nyXDb"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agPRGolUmFA3"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "# функция разбивает текст на предложения\n",
        "def cut_text_by_sent(text, fragment_len=200, overlay=100):\n",
        "    # text - исходный текст\n",
        "    # fragment_len - длина каждого фрагмента текста (по умолчанию 200)\n",
        "    # overlay - перекрытие между фрагментами\n",
        "    sentences = sent_tokenize(text)\n",
        "    fragments = []\n",
        "    current_fragment = []\n",
        "    current_len = 0\n",
        "    # проход по каждому предложению\n",
        "    for sent in sentences:\n",
        "        # если предложение короче 200 символов, то оно объединяется с соседним\n",
        "        if current_len + len(sent) <= fragment_len:\n",
        "            current_fragment.append(sent)\n",
        "            current_len += len(sent)\n",
        "        # если длиннее, то запись в \"ячейку\" заканчивается\n",
        "        else:\n",
        "            if current_fragment:\n",
        "                fragments.append(' '.join(current_fragment))\n",
        "            current_fragment = [sent]\n",
        "            current_len = len(sent)\n",
        "\n",
        "    final_fragments = []\n",
        "    # если предложение очень длинное, то оно разбивается на несколько ячеек\n",
        "    for fragment in fragments:\n",
        "        if len(fragment) > fragment_len:\n",
        "            all_len = 0\n",
        "            len_text = len(fragment)\n",
        "\n",
        "            while all_len + fragment_len <= len_text:\n",
        "                final_fragments.append(fragment[all_len:all_len + fragment_len])\n",
        "                all_len += overlay\n",
        "        else:\n",
        "            final_fragments.append(fragment)\n",
        "\n",
        "    return final_fragments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWTNiKZYhev2"
      },
      "outputs": [],
      "source": [
        "# Проверка\n",
        "text = 'Необходимо записать ваш датасет в векторную базу данных и выполнить эксперименты по поиску схожих фрагментов текста, соответствующих запросу. Дополнительные баллы: провести эксперименты с разными системами векторизации и алгоритмами similarity. Сравнить средний порядковый номер требуемого фрагмента в отсортированном по релевантности спике результатов. Примеры классов, которые могут потребоваться для выполнения данного задания описаны в ноутбуке.'\n",
        "text_fragments = cut_text_by_sent(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVIO8tzktmdo"
      },
      "outputs": [],
      "source": [
        "text_fragments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne0K8t4TqtpA",
        "outputId": "864530df-4c12-438b-fa6d-6902ad9c8cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[141, 102, 108]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "[len(f) for f in text_fragments]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3RPY08gt3U5"
      },
      "source": [
        "# **paraphrase-multilingual-mpnet-base-v2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upzMcA7t9PLb"
      },
      "outputs": [],
      "source": [
        "class Loader:\n",
        "  # загружает одиночный документ из указанного файла\n",
        "  def load_single_document(self, file_path: str):\n",
        "    pass\n",
        "\n",
        "  # загружает документы из указанной директории\n",
        "  def load_documents(self, source_dir: str):\n",
        "    pass\n",
        "\n",
        "class Embedder():\n",
        "  # векторизация текстовых предложений с использованием модели SentenceTransformer\n",
        "  def __init__(self):\n",
        "    self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
        "\n",
        "  # возвращает векторные представления для заданных предложений\n",
        "  def get_embeddings(self, sentences):\n",
        "    return [[float(e) for e in list(emb)] for emb in list(self.model.encode(sentences))]\n",
        "\n",
        "class ChromaDB():\n",
        "  # инициализация клиента ChromaDB\n",
        "  def __init__(self):\n",
        "    # использование клиента без сохранения на диск\n",
        "    # self.client = chromadb.Client()\n",
        "    # создает клиента с постоянным хранением на диске\n",
        "    self.client = chromadb.PersistentClient(path=\"/content/gdrive/MyDrive/nlp\")\n",
        "\n",
        "  # удаление коллекции с указанным именем\n",
        "  def clear(self, name):\n",
        "    self.client.delete_collection(name=name)\n",
        "    return self.client.list_collections()\n",
        "\n",
        "  # получение коллекции с указанным именем\n",
        "  def get_collection(self, name):\n",
        "    return self.client.get_collection(name=name)\n",
        "\n",
        "  # возвращение списка доступных коллекций\n",
        "  def get_collections(self):\n",
        "    return self.client.list_collections()\n",
        "\n",
        "class ChromaCollection():\n",
        "  # инициализация коллекции с заданным именем, схожестью и клиентом ChromaDB\n",
        "  def __init__(self, collection_name, similarity, client):\n",
        "    self.collection_name = collection_name\n",
        "    self.similarity = similarity\n",
        "    self.client = client\n",
        "    self.collection = self.client.get_or_create_collection(name=collection_name, metadata={\"hnsw:space\": similarity})\n",
        "\n",
        "  # добавление документов в коллекцию с соответствующими метаданными (темами)\n",
        "  def add(self, embeddings, texts, topics, ids):\n",
        "    self.collection.add(\n",
        "        embeddings = embeddings,\n",
        "         documents = texts,\n",
        "         metadatas = [{\"source\": \"df\", \"topic\":f\"{topic}\"} for i, topic in enumerate(topics)],\n",
        "         ids = [f'id {i}' for i in ids]\n",
        ")\n",
        "\n",
        "  # поиск схожих документов в коллекции на основе заданных эмбеддингов и возвращает указанное кол-во результатов\n",
        "  def query(self, embeddings, n_results):\n",
        "    return self.collection.query(\n",
        "      query_embeddings=embeddings,\n",
        "       n_results=n_results,\n",
        "    )\n",
        "\n",
        "  # возвращение всех документов в коллекции\n",
        "  def get(self):\n",
        "    return self.collection.get()\n",
        "\n",
        "  # возвращение кол-ва документов в коллекции\n",
        "  def count(self):\n",
        "    return self.collection.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyEvT0079POX"
      },
      "outputs": [],
      "source": [
        "# создается объект класса Embedder и присваивается переменной embedder\n",
        "embedder = Embedder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtLayPDk-puh"
      },
      "outputs": [],
      "source": [
        "embeds = embedder.get_embeddings(df['text'][:30000])\n",
        "#embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld89Sh_pPQRk"
      },
      "outputs": [],
      "source": [
        "# объявление объекта класса ChromaDB, который может быть использован для выполнения операций в векторной БД\n",
        "client = ChromaDB()\n",
        "client.get_collections()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCq1Dyq1IJv1"
      },
      "source": [
        "* **Косинусное сходство (Cosine Similarity)**: Этот алгоритм измеряет косинус угла между двумя векторами, представляющими текстовые фрагменты. Более высокое значение косинусного сходства указывает на более близкое сходство между фрагментами.\n",
        "* **Евклидово расстояние (Euclidean Distance)**: Этот алгоритм измеряет расстояние между двумя точками в n-мерном пространстве. Для текстовых фрагментов, которые представлены как точки в пространстве, меньшее значение евклидова расстояния указывает на более близкое сходство.\n",
        "* **IP-расстояние (Integral Projection Distance)**: Этот алгоритм измеряет сходство между двумя распределениями, основываясь на их форме и значении проекций. Для этого оно вычисляет площадь между интегральными проекциями двух распределений. Чем меньше площадь между проекциями, тем больше схожесть между распределениями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL4AI3HKNLQT"
      },
      "outputs": [],
      "source": [
        "# 'cos_sim', 'l2_sim' и 'Ip_sim' - имена коллекций, которые будут созданы в БД ChromaDB\n",
        "# 'cosine', 'l2' и 'ip' - типы схожести (similarity) для каждой коллекции.\n",
        "# cosine - косинусное расстояние\n",
        "# l2 - евклидово расстояние\n",
        "# ip - произведение скалярного умножения\n",
        "# client.client - объект клиента ChromaDB, через который будет осуществляться доступ к БД\n",
        "collection_cos = ChromaCollection('cos_sim', 'cosine', client.client)\n",
        "collection_l2 = ChromaCollection('l2_sim', 'l2', client.client)\n",
        "collection_Ip = ChromaCollection('Ip_sim', 'ip', client.client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sieYB3l1CytN"
      },
      "outputs": [],
      "source": [
        "# добавление документов в каждую из трех коллекций в векторную БД\n",
        "# embeds - векторные представления документов, которые нужно добавить в коллекцию\n",
        "# texts - тексты документов, которые нужно добавить в коллекцию\n",
        "# topics - темы (метаданные) документов, которые нужно добавить в коллекцию\n",
        "# ids - идентификаторы документов, которые нужно добавить в коллекцию\n",
        "collection_cos.add(embeds[0:30000], df['text'].values.tolist()[0:30000], df['topic'].values.tolist()[0:30000], df['ID'].values.tolist()[0:30000])\n",
        "collection_l2.add(embeds[0:30000], df['text'].values.tolist()[0:30000], df['topic'].values.tolist()[0:30000], df['ID'].values.tolist()[0:30000])\n",
        "collection_Ip.add(embeds[0:30000], df['text'].values.tolist()[0:30000], df['topic'].values.tolist()[0:30000], df['ID'].values.tolist()[0:30000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P3Z79i4C6o2"
      },
      "outputs": [],
      "source": [
        "print(collection_cos.count())\n",
        "print(collection_l2.count())\n",
        "print(collection_Ip.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkQtuFejXwVc"
      },
      "outputs": [],
      "source": [
        "# берем строчку из датасета и формируем по ней вопрос\n",
        "questions = [\n",
        "    # Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
        "    'What are short-sellers seeing again?',\n",
        "    # Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
        "    'What is Carlyle Group known for?',\n",
        "    # Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
        "    'What factors are expected to hang over the stock market next week?',\n",
        "    # Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n",
        "    'Why have authorities halted oil export flows from the main pipeline in southern Iraq?',\n",
        "    # Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n",
        "    'What economic menace do world oil prices present?',\n",
        "\n",
        "    # Was absenteeism a little high\\on Tuesday among the guys at the office? EA Sports would like\\to think it was because \"Madden NFL 2005\" came out that day,\\and some fans of the football simulation are rabid enough to\\take a sick day to play it.\n",
        "    'Why was the absenteeism high on Tuesday among the guys at the office?',\n",
        "    # A group of technology companies\\including Texas Instruments Inc. (TXN.N), STMicroelectronics\\(STM.PA) and Broadcom Corp. (BRCM.O), on Thursday said they\\will propose a new wireless networking standard up to 10 times\\the speed of the current generation.\n",
        "    'Which technology companies are proposing a new wireless networking standard with speeds up to 10 times faster than the current generation?',\n",
        "    # America Online on Thursday said it\\plans to sell a low-priced PC targeting low-income and minority\\households who agree to sign up for a year of dialup Internet\\service.\n",
        "    'What is the plan of America Online to target low-income and minority households with a low-priced PC and a year of dial-up Internet service?',\n",
        "    # A group of consumer electronics\\makers said on Wednesday they approved the format for a new\\generation of discs that can store five times the data of DVDs\\at the same cost -- enough to put a full season of \"The\\Sopranos\" on one disc.\n",
        "    'Which consumer electronics makers have approved the format for new discs capable of storing five times more data than DVDs?',\n",
        "    # The mystery of what went wrong for the\\software industry in late June when sales stalled at more than\\20 brand-name companies is not even close to being solved\\although the third quarter is nearly halfway over.\n",
        "    'What is the current status of solving the mystery behind the software industry sales slump in late June, despite being halfway through the third quarter?',\n",
        "\n",
        "    # Michael Phelps took care of qualifying for the Olympic 200-meter freestyle semifinals Sunday, and then found out he had been added to the American team for the evening's 400 freestyle relay final. Phelps' rivals Ian Thorpe and Pieter van den Hoogenband and teammate Klete Keller were faster than the teenager in the 200 free preliminaries.\n",
        "    'Who did take care of qualifying for the Olympic 200-meter freestyle semifinals Sunday?',\n",
        "    # Wily Mo Pena homered twice and drove in four runs, helping the Cincinnati Reds beat the San Diego Padres 11-5 on Saturday night. San Diego was knocked out of a share of the NL wild-card lead with the loss and Chicago's victory over Los Angeles earlier in the day.\n",
        "    'How did Wily Mo Pena contribute to the Cincinnati Reds victory over the San Diego Padres?',\n",
        "    # National Basketball Association players trying to win a fourth consecutive Olympic gold medal for the United States have gotten the wake-up call that the \"Dream Team\" days are done even if supporters have not.\n",
        "    'What realization have National Basketball Association players had about the chances of winning a fourth consecutive Olympic gold medal?',\n",
        "    # The Cleveland Indians pulled within one game of the AL Central lead, scoring four runs in the first inning and beating the Minnesota Twins 7-1 Saturday night behind home runs by Travis Hafner and Victor Martinez.\n",
        "    'How did the Cleveland Indians narrow the gap in the AL Central standings with their win over the Minnesota Twins?',\n",
        "    # Kevin Hartman made seven saves for Los Angeles, and Jon Busch had two saves for Columbus as the Galaxy and Crew played to a 0-0 tie Saturday night.\n",
        "    'How did the goalkeepers Kevin Hartman and Jon Busch influence the outcome of the match between the Los Angeles Galaxy and Columbus Crew?',\n",
        "\n",
        "    # Venezuelans turned out early\\and in large numbers on Sunday to vote in a historic referendum\\that will either remove left-wing President Hugo Chavez from\\office or give him a new mandate to govern for the next two\\years.\n",
        "    'What is the purpose of the historic referendum in Venezuela that drew a large voter turnout?',\n",
        "    # South Korean police used water cannon in\\central Seoul Sunday to disperse at least 7,000 protesters\\urging the government to reverse a controversial decision to\\send more troops to Iraq.\n",
        "    'Why did South Korean police use water cannon to disperse thousands of protesters in central Seoul?',\n",
        "    # Thousands of Palestinian\\prisoners in Israeli jails began a hunger strike for better\\conditions Sunday, but Israel's security minister said he\\didn't care if they starved to death.\n",
        "    'What initiated the hunger strike by thousands of Palestinian prisoners in Israeli jails, despite concerns over their well-being?',\n",
        "    # Sporadic gunfire and shelling took place overnight in the disputed Georgian region of South Ossetia in violation of a fragile ceasefire, wounding seven Georgian servicemen.\n",
        "    'What happened in the disputed Georgian region of South Ossetia overnight, violating the fragile ceasefire and causing injuries to Georgian servicemen?',\n",
        "    # Dozens of Rwandan soldiers flew into Sudan's troubled Darfur region Sunday, the first foreign armed force deployed in the area since Arab militiamen began a rampage against black African farmers, killing thousands.\n",
        "    'What is the significance of the deployment of Rwandan soldiers to Sudan troubled Darfur region amidst the ongoing violence between Arab militiamen and black African farmers?'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0R08PRRrBM6"
      },
      "outputs": [],
      "source": [
        "# генерация эмбедингов для списка вопросов\n",
        "q_embeds = embedder.get_embeddings(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvB4gg4sX1fx"
      },
      "outputs": [],
      "source": [
        "# ожидаемое максимальное кол-во результатов поиска до 1000\n",
        "results_cos = collection_cos.query(q_embeds,1000)\n",
        "# вывод первых 10-ти результатов\n",
        "results_cos['documents'][0][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au8JN2T8FMeW"
      },
      "outputs": [],
      "source": [
        "ind_cos = []\n",
        "for i, res in enumerate(results_cos['ids']):\n",
        "  try:\n",
        "    ind_cos.append(res.index(f'id {i}'))\n",
        "  except:\n",
        "    ind_cos.append(1000)\n",
        "\n",
        "print(sum(ind_cos) / len(ind_cos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciYOE1RSX975"
      },
      "outputs": [],
      "source": [
        "results_l2 = collection_l2.query(q_embeds,1000)\n",
        "results_l2['documents'][0][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GusaRsp6X_sZ"
      },
      "outputs": [],
      "source": [
        "ind_l2 = []\n",
        "for i, res in enumerate(results_l2['ids']):\n",
        "  try:\n",
        "    ind_l2.append(res.index(f'id {i}'))\n",
        "  except:\n",
        "    ind_l2.append(1000)\n",
        "sum(ind_l2) / len(ind_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgfqRekcYGXx"
      },
      "outputs": [],
      "source": [
        "results_ip = collection_Ip.query(q_embeds,1000)\n",
        "results_ip['documents'][0][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlSUSo1aYG1e"
      },
      "outputs": [],
      "source": [
        "ind_ip = []\n",
        "for i, res in enumerate(results_ip['ids']):\n",
        "  try:\n",
        "    ind_ip.append(res.index(f'id {i}'))\n",
        "  except:\n",
        "    ind_ip.append(1000)\n",
        "\n",
        "sum(ind_ip) / len(ind_ip)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Лабораторная работа №6 (Question Answering)**"
      ],
      "metadata": {
        "id": "Z2C1AvPb6L8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    'What are short-sellers seeing again?',\n",
        "    'What is Carlyle Group known for?',\n",
        "    'What factors are expected to hang over the stock market next week?',\n",
        "    'Why have authorities halted oil export flows from the main pipeline in southern Iraq?',\n",
        "    'What economic menace do world oil prices present?',\n",
        "\n",
        "    'Why was the absenteeism high on Tuesday among the guys at the office?',\n",
        "    'Which technology companies are proposing a new wireless networking standard with speeds up to 10 times faster than the current generation?',\n",
        "    'What is the plan of America Online to target low-income and minority households with a low-priced PC and a year of dial-up Internet service?',\n",
        "    'Which consumer electronics makers have approved the format for new discs capable of storing five times more data than DVDs?',\n",
        "    'What is the current status of solving the mystery behind the software industry sales slump in late June, despite being halfway through the third quarter?',\n",
        "\n",
        "    'Who did take care of qualifying for the Olympic 200-meter freestyle semifinals Sunday?',\n",
        "    'How did Wily Mo Pena contribute to the Cincinnati Reds victory over the San Diego Padres?',\n",
        "    'What realization have National Basketball Association players had about the chances of winning a fourth consecutive Olympic gold medal?',\n",
        "    'How did the Cleveland Indians narrow the gap in the AL Central standings with their win over the Minnesota Twins?',\n",
        "    'How did the goalkeepers Kevin Hartman and Jon Busch influence the outcome of the match between the Los Angeles Galaxy and Columbus Crew?',\n",
        "\n",
        "    'What is the purpose of the historic referendum in Venezuela that drew a large voter turnout?',\n",
        "    'Why did South Korean police use water cannon to disperse thousands of protesters in central Seoul?',\n",
        "    'What initiated the hunger strike by thousands of Palestinian prisoners in Israeli jails, despite concerns over their well-being?',\n",
        "    'What happened in the disputed Georgian region of South Ossetia overnight, violating the fragile ceasefire and causing injuries to Georgian servicemen?',\n",
        "    'What is the significance of the deployment of Rwandan soldiers to Sudan troubled Darfur region amidst the ongoing violence between Arab militiamen and black African farmers?'\n",
        "\n",
        "    'Who won the FIFA World Cup in 2018?',\n",
        "    'Who is the 46th President of the United States?',\n",
        "    'Which country hosted the 2020 Summer Olympics?',\n",
        "    'What is the most popular social media platform worldwide?',\n",
        "    'Which sport requires the use of a shuttlecock?',\n",
        "    'Who is the CEO of Tesla Inc.?',\n",
        "    'What is the currency of Japan?',\n",
        "    'What is the fastest land animal?',\n",
        "    'What is the capital of Australia?',\n",
        "    'Who wrote the play \"Romeo and Juliet\"?'\n",
        "]\n",
        "\n",
        "answers = ['Green',\n",
        "           'Making well-timed and occasionally controversial plays in the defense industry',\n",
        "           'Soaring crude prices, worries about the economy, and the outlook for earnings',\n",
        "           'Due to intelligence showing a potential strike on infrastructure by a rebel militia',\n",
        "           'They present a new economic threat/menace before the US presidential elections',\n",
        "\n",
        "           'Because of the release of \"Madden NFL 2005\" football simulation game',\n",
        "           'Texas Instruments Inc',\n",
        "           'To sell a low-priced PC to low-income and minority households who sign up for a year of dial-up Internet service',\n",
        "           'A group of consumer electronics makers',\n",
        "           'The mystery is still far from being solved',\n",
        "\n",
        "           'Michael Phelps',\n",
        "           'He homered twice and drove in four runs',\n",
        "           'The \"Dream Team\" days are done',\n",
        "           'They scored four runs in the first inning and got home runs by Travis Hafner and Victor Martinez',\n",
        "           'They made saves for their respective teams, resulting in a 0-0 tie',\n",
        "\n",
        "           'To remove left-wing President Hugo Chavez from office or give him a new mandate to govern for the next two years',\n",
        "           'The protesters were urging the government to reverse a controversial decision to send more troops to Iraq',\n",
        "           'The prisoners initiated the hunger strike to demand better conditions',\n",
        "           'Sporadic gunfire and shelling took place, resulting in injuries to seven Georgian servicemen',\n",
        "           'African farmers were killing thousands',\n",
        "\n",
        "           'France',\n",
        "           'Joe Biden',\n",
        "           'Japan (Tokyo)',\n",
        "           'Facebook',\n",
        "           'Badminton',\n",
        "           'Elon Musk',\n",
        "           'Japanese yen',\n",
        "           'Cheetah',\n",
        "           'Canberra',\n",
        "           'William Shakespeare']"
      ],
      "metadata": {
        "id": "tCljSkmS6Pd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализация вопросно-ответной модели roberta-base-squad2\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)"
      ],
      "metadata": {
        "id": "Z4sFux8m6aUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторные представления для заданных вопросов\n",
        "q_embeds = embedder.get_embeddings(questions)\n",
        "# возвращение 5-ти подходящих результатов для каждого вопроса\n",
        "results = collection_cos.query(q_embeds,5)\n",
        "# из 5-ти вариантов выводим первый\n",
        "results['documents'][0]"
      ],
      "metadata": {
        "id": "qHaCFTOz6Vnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score\n",
        "from evaluate import load\n",
        "# предобученная модель для оценки качества\n",
        "bertscore = load(\"bertscore\")"
      ],
      "metadata": {
        "id": "AjqmpqI26bsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# список для хранения результатов bertscore\n",
        "bs_all = []\n",
        "# q - вопрос, a - ответ на вопрос, index - индекс вопроса\n",
        "for q, a, index in zip(questions, answers, range(len(answers))):\n",
        "  # создается словарь для вопроса и контента из датасета\n",
        "  QA_input = {'question': q,\n",
        "             'context': ' '.join(results['documents'][index])}\n",
        "  res = nlp(QA_input)\n",
        "  # вычисляет метрику BERTScore между предсказанным ответом и референсным ответом\n",
        "  bs = bertscore.compute(predictions=[res['answer']], references=[a], lang=\"en\")\n",
        "  bs_all.append(bs)\n",
        "\n",
        "  # результат оценки для каждой пары вопрос - ответ\n",
        "  print(f'Question: {q}\\nAnswer: {res[\"answer\"]}\\nUser answer: {a}\\nScore: {bs[\"f1\"][0]}\\n ')"
      ],
      "metadata": {
        "id": "1wyRvr-z6dSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# среднее значение метрики по всем вопросам\n",
        "f1_scores = [bs['f1'][0] for bs in bs_all]\n",
        "sum(f1_scores)/len(f1_scores)"
      ],
      "metadata": {
        "id": "Rb674eT36e2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradio**"
      ],
      "metadata": {
        "id": "G5adSr-b6vxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.48.0\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Epi582bw6op3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функция принимает вопрос, ищет подходящий контент и генерирует ответ на вопрос\n",
        "def echo(question, history):\n",
        "    q_embeds = embedder.get_embeddings([question])\n",
        "    # выполнение поиска схожих документов в коллекции\n",
        "    results = collection_cos.query(q_embeds,5)\n",
        "    QA_input = {'question': question,\n",
        "             'context': ' '.join(results['documents'][0])}\n",
        "    res = nlp(QA_input)\n",
        "    return res['answer']"
      ],
      "metadata": {
        "id": "OJQDhmAj61T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# графический интерфейс\n",
        "demo = gr.ChatInterface(fn=echo, examples=[\"hello\", \"hola\", \"merhaba\"], title=\"QA Bot\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "QbQjrJkE62t3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}